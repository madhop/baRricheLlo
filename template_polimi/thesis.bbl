\begin{thebibliography}{1}

\bibitem{ahura}
M.~R. {Bonyadi}, Z.~{Michalewicz}, S.~{Nallaperuma}, and F.~{Neumann}.
\newblock Ahura: A heuristic-based racer for the open racing car simulator.
\newblock {\em IEEE Transactions on Computational Intelligence and AI in
  Games}, 9(3):290--304, 2017.

\bibitem{botta}
M.~{Botta}, V.~{Gautieri}, D.~{Loiacono}, and P.~L. {Lanzi}.
\newblock Evolving the optimal racing line in a high-end racing game.
\newblock In {\em 2012 IEEE Conference on Computational Intelligence and Games
  (CIG)}, pages 108--115, 2012.

\bibitem{cardamone}
L.~{Cardamone}, D.~{Loiacono}, and P.~L. {Lanzi}.
\newblock Learning drivers for torcs through imitation using supervised
  methods.
\newblock In {\em 2009 IEEE Symposium on Computational Intelligence and Games},
  pages 148--155, 2009.

\bibitem{cmaes}
N.~{Hansen}, S.~D. {MÃ¼ller}, and P.~{Koumoutsakos}.
\newblock Reducing the time complexity of the derandomized evolution strategy
  with covariance matrix adaptation (cma-es).
\newblock {\em Evolutionary Computation}, 11(1):1--18, 2003.

\bibitem{atari}
Silver Mnih, Kavukcuoglu.
\newblock Playing atari with deep reinforcement learning.

\bibitem{alphago}
Maddison Silver, Huang.
\newblock Mastering the game of go with deep neural networks and tree search.
\newblock {\em Nature}, 2016.

\bibitem{mpc_orig}
Yu-Geng XI, Dewei Li, and Shu Lin.
\newblock Model predictive control - status and challenges.
\newblock {\em Acta Automatica Sinica}, 39, 03 2013.

\bibitem{cinesi}
Zhu Zuo, Wang.
\newblock Continuous reinforcement learning from human demonstrations with
  integrated experience replay for autonomous driving.
\newblock {\em International Conference on Robotics and Biometrics}, 2017.

\end{thebibliography}
