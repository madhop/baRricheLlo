\chapter{Introduction}
\label{Introduction}
\thispagestyle{empty}
\pagenumbering{arabic}




Autonomous driving is a hot topic in research, especially concerning fields of computer science, artificial intelligence, robotics and electronics, together with  automotive, military, racing cars, flight firms. The main goal is to disrupt the need of a human driver or pilot, resulting in a reduction in costs and an increase of safety, for instance by reducing the number of accidents per-year due to human error.
There are many reasons that push the research of autonomous driving, especially concerning cars:
statistics say that 94\% of fatal accidents are due to human error \cite{acc_stat}. This could be eradicated by letting an algorithm tacking decisions in the traffic in a more efficient way.
Other reasons are costs and performances: before launching a new car model on the market, car manufacturers need to extensively test the vehicle, and this involves paying a pilot to do that; autonomous testing could avoid this cost; moreover, costs of car manufacturing and of fuel consumption add up. Finally, a human driver owns an intrinsic variability: sleep, distraction, chatting with another person may alter driving performances. A driver algorithm completely avoid these issues.
In the world of racing, autonomous cars could allow car manufacturers to test several car components simultaneously on the tracks and select the best ones, in order to achieve the best dynamical properties.
Another aspect is energy and time efficiency: in an urban environment, multiple cars interacting wirelessly could communicate and plan routes and low level actions in a way to avoid clogs.
Autonomous driving can be defined as the capability of an agent -be it physical or virtual- of perceiving the environment and moving accordingly in order to follow a path and reach a specific target.
The physical agent consists in a piece of hardware equipped with one or more motors, being they cars, drones, UAV (Unmanned Aerial Vehicles), military vehicles. They are equipped with some sensors to have an insight on the environment, one or more computer units with a decision making algorithm, which compute an action to perform by means of some actuators, such as a throttle, a break, a steering, or a transmission.
Concerning the virtual world, autonomous driving is common in videogames and simulators, and the advances of the algorithms enhance more and more their performance and realism compared to human driving.
Autonomous driving is a topic of research since '40s. However, it is only in the last decade that it has seen the main progress. Thanks to the software and hardware evolution. From the software point of view, Machine Learning (ML), and in particular Deep Learning (DL), laid the foundation for an autonomous learning, without the explicit programming by the hand of a human. Due to the complexity of the computations needed to achieve this goal, it is only thanks to recent advances in GPUs that this paradigm has started being feasible in practice.
The most promising branch which is been leading the progress in autonomous driving is Reinforcement Learning (RL). In the RL paradigm an autonomous agent learns to improve its performance at an assigned task by interacting with its environment. RL agents are not told explicitly how to act by an expert; rather an agentâ€™s performance is evaluated by a reward signal.
For this reason, RL has proven to be successful in the fields where the dynamics are very complex or not known.
It led to excellent results in the training of such agents for controlling real-world systems such as robots or helicopters.
Recent work also shows promising applications of RL for autonomous driving by making strategic decisions. 
Autonomous driving tasks where RL could be applied include: controller optimization, path planning and trajectory optimization, motion planning and dynamic path planning, development of high-level driving policies for complex navigation tasks, scenario-based policy learning for highways, intersections, merges and splits, reward learning with inverse reinforcement learning from expert data for intent prediction for traffic actors such as pedestrian, vehicles and finally learning of policies that ensures safety and perform risk estimation. Further, it turns out to be suitable in contexts of autonomous racing: the driverless racer could learn a policy that is able to outperform the performance of a human driver, or a policy taught by experts.

\section{Thesis Goal}

In general, finding the optimal racing line is a common problem in real-world car racing as well as in the development of commercial racing games.
The aim of our research is to provide autonomous driving algorithms for racing cars in order to assist professional drivers to improve their racing line.
In this case, the ultimate goal of our driver model is to drive the car around a racing track so as to achieve the lowest possible lap-time, preferably by reaching the physical limits of the car.
Traditionally, it is the result of technical studies conduced by experts, which analyze the shape of the track and, taking into account the dynamics of the vehicle and the environment, formulate the best strategies to obtain the best possible trajectory. Then, the pilot must be able to follow the shaped trajectory in order to perform the best time.
Our approach is the opposite: after collecting racing demonstrations with different human pilots, we select the best lap as \textit{reference trajectory}. Our goal is to develop an algorithm capable of following this reference trajectory and possibly outperform it in terms of lap-time.
In the literature, autonomous driving problems have been solved by exploiting image processing, to analyze information based on images from cameras. However, in general, processing video input takes significant time and resources in training phases: from rendering to learning from them. Instead, a physics engine for racing simulation often runs headless to produce telemetry data at high rates, and racing cars already have the infrastructure to capture and make use of telemetry data which could be utilised for our purpose.
In this work we will illustrate different techniques of Reinforcement Learning exploited to find the optimal racing line by using telemetry data, including strategies which embodies human past experience to replicate behaviours -or even improve them. 



