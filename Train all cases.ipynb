{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%aimport os, pandas, numpy, pickle\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from sklearn.ensemble.forest import ExtraTreesRegressor\n",
    "\n",
    "from fqi.et_tuning import run_tuning\n",
    "from fqi.reward_function import *\n",
    "from fqi.sars_creator import to_SARS\n",
    "from fqi.utils import *\n",
    "\n",
    "from trlib.policies.valuebased import EpsilonGreedy, Softmax\n",
    "from trlib.policies.qfunction import ZeroQ\n",
    "from trlib.algorithms.reinforcement.fqi_driver import FQIDriver, DoubleFQIDriver\n",
    "from trlib.environments.trackEnv import TrackEnv\n",
    "from trlib.utilities.ActionDispatcher import *\n",
    "\n",
    "from fqi.fqi_evaluate import run_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(track_file_name, rt_file_name, data_path, max_iterations, output_path, n_jobs,\n",
    "                   output_name, reward_function, r_penalty, r_offroad_penalty, rp_kernel, rp_band, ad_type, tuning,\n",
    "                   tuning_file_name, kdt_norm, kdt_param, filt_a_outliers, double_fqi, evaluation, first_step):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_file_name = 'dataset_offroad'\n",
    "rt_file_name = 'ref_traj'\n",
    "data_path = './trajectory/'\n",
    "max_iterations = 100\n",
    "output_path = './model_file/'\n",
    "n_jobs = 10\n",
    "\n",
    "r_penalty = True\n",
    "r_offroad_penalty = True\n",
    "\n",
    "reward_function = 'temporal'\n",
    "output_name = reward_function + ('_penalty' if r_penalty else '') + '_reward_model'#'first_model'\n",
    "\n",
    "\n",
    "rp_kernel = 'exponential'\n",
    "rp_band = 0.88586679\n",
    "\n",
    "filter_actions = False\n",
    "filt_a_outliers = False\n",
    "evaluation = True\n",
    "\n",
    "first_step = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment(track_file_name, rt_file_name, data_path, max_iterations, output_path, n_jobs,\n",
    "                   output_name, reward_function, r_penalty, r_offroad_penalty, rp_kernel, rp_band, 'rkdt', False,\n",
    "                   '', False, 10, filt_a_outliers, True, evaluation, first_step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
